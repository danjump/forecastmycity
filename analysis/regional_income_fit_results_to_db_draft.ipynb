{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import getopt\n",
    "import pandas as pd\n",
    "# import MySQLdb as mdb\n",
    "from sqlalchemy import create_engine\n",
    "from sqlalchemy.exc import OperationalError\n",
    "import re\n",
    "import shelve\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "resultsdir = './results/regional_income/'\n",
    "\n",
    "manf = []\n",
    "rettrd = []\n",
    "\n",
    "for fn in os.listdir(resultsdir):\n",
    "    # if os.path.isfile(fn):\n",
    "    m_manf = re.search('results.*manf.*\\.shelf',fn)\n",
    "    if m_manf:\n",
    "        \n",
    "        shelf = shelve.open(resultsdir+fn, 'r')\n",
    "        args_dict = shelf['args_dict']\n",
    "        shelf.close()\n",
    "        \n",
    "        manf.append(args_dict)\n",
    "    else:\n",
    "        m_rettrd = re.search('results.*rettrd.*\\.shelf',fn)\n",
    "        if m_rettrd:\n",
    "\n",
    "            shelf = shelve.open(resultsdir+fn, 'r')\n",
    "            args_dict = shelf['args_dict']\n",
    "            shelf.close()\n",
    "            \n",
    "            rettrd.append(args_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def dict_to_dfs(args_dict):\n",
    "    # dictionary that will be filled, then used to fill a df\n",
    "    fill_dict = {}\n",
    "    \n",
    "    # first add datapoint entries\n",
    "    fill_dict['data'] = {}\n",
    "    fill_dict['data']['x'] = []\n",
    "    fill_dict['data']['y'] = []\n",
    "    fill_dict['data']['case'] = []\n",
    "    fill_dict['data']['geofips'] = []\n",
    "    fill_dict['data']['industry'] = []\n",
    "    \n",
    "    # manually select & name the coordinate pair cases\n",
    "    for x_name, y_name, case in [('X_train', 'Y_train', 'data_train'),\n",
    "                                   ('X_full', 'Y_full', 'data_full'),\n",
    "                                   ('X_test', 'Y_test', 'data_test'),\n",
    "                                   ('X_train', 'ypred_train', 'pred_train'),\n",
    "                                   ('X_full', 'ypred_full', 'pred_full'),\n",
    "                                   ('X_test', 'ypred_test', 'pred_test'),\n",
    "                                   ('Xproj_train', 'yproj_train', 'proj_train'),\n",
    "                                   ('Xproj_full', 'yproj_full', 'proj_full')]:\n",
    "        for x,y in zip(args_dict[x_name],args_dict[y_name]):\n",
    "            fill_dict['data']['x'].append(x)\n",
    "            fill_dict['data']['y'].append(y)\n",
    "            fill_dict['data']['case'].append(case)\n",
    "            fill_dict['data']['geofips'].append(args_dict['geofips'])\n",
    "            fill_dict['data']['industry'].append(args_dict['industry'])\n",
    "\n",
    "    # loop to fill the rest of the data\n",
    "    fill_dict['attributes'] = {}\n",
    "    fill_dict['fit_scores'] = {}\n",
    "    for key in args_dict:\n",
    "        # skip the arrays/lists\n",
    "        if type(args_dict[key]) == type([]) or type(args_dict[key]) == type(np.array([])):\n",
    "            continue\n",
    "            \n",
    "        # for dictionary entries (i.e. the fit scores)\n",
    "        elif type(args_dict[key]) == type({}):\n",
    "            if 'geofips' not in fill_dict['fit_scores']:\n",
    "                fill_dict['fit_scores']['geofips'] = []\n",
    "            if 'industry' not in fill_dict['fit_scores']:\n",
    "                fill_dict['fit_scores']['industry'] = []\n",
    "            if 'case' not in fill_dict['fit_scores']:\n",
    "                fill_dict['fit_scores']['case'] = []\n",
    "                    \n",
    "            fill_dict['fit_scores']['geofips'].append(args_dict['geofips'])\n",
    "            fill_dict['fit_scores']['industry'].append(args_dict['industry'])\n",
    "            fill_dict['fit_scores']['case'].append(key)\n",
    "            \n",
    "            for subkey in args_dict[key]:\n",
    "                if subkey not in fill_dict['fit_scores']:\n",
    "                    fill_dict['fit_scores'][subkey] = []\n",
    "                fill_dict['fit_scores'][subkey].append(args_dict[key][subkey])\n",
    "        \n",
    "        else:\n",
    "            fill_dict['attributes'][key] = [args_dict[key]]\n",
    "            \n",
    "    df_dict = {}\n",
    "    for entry in fill_dict:\n",
    "        df_dict[entry] = pd.DataFrame(fill_dict[entry])\n",
    "        \n",
    "    return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_to_sql(df, name):\n",
    "    try:\n",
    "        # print 'Connecting to database...'\n",
    "        # con = mdb.connect('localhost', 'danielj', '', 'ecotest')\n",
    "        engine = create_engine(\n",
    "            \"mysql+mysqldb://danielj:@localhost/ecotest\")\n",
    "    except:\n",
    "        print 'Error connecting to db:', sys.exc_info()[0]\n",
    "        return 0\n",
    "    try:\n",
    "        # print 'Writing to database table:%s'%name\n",
    "        df.to_sql(con=engine, name=name,\n",
    "                  if_exists='append', flavor='mysql')\n",
    "    except OperationalError as err:\n",
    "        print 'Error writing to db:', sys.exc_info()[0]\n",
    "        print err.message\n",
    "        return 0\n",
    "    return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def write_all_to_sql(tmp_dict):\n",
    "    n_tmp_dict = len(tmp_dict)\n",
    "\n",
    "    for entry,count in zip(tmp_dict,range(1,n_tmp_dict+1)):\n",
    "        df_dict = dict_to_dfs(entry)\n",
    "        for name in df_dict:\n",
    "            write_to_sql(df_dict[name], name)\n",
    "\n",
    "        sys.stdout.write('\\rProgress: %d/%d' % (count, n_tmp_dict))\n",
    "        sys.stdout.flush()\n",
    "\n",
    "    print '\\ndone!'\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: 375/375\n",
      "done!\n"
     ]
    }
   ],
   "source": [
    "write_all_to_sql(rettrd)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
